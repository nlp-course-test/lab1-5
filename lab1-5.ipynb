{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS187\n",
    "## Lab 1-5 â€“ Scaling up: Torchtext and PyTorch\n",
    "\n",
    "The pipeline for NLP applications based on supervised machine learning involves several standard components:\n",
    "\n",
    "1. Loading of annotated textual corpora.\n",
    "2. Tokenization and normalization of the text.\n",
    "3. Distributing instances into subcorpora, for instance, training, development, and test corpora.\n",
    "4. Training of models on training data.\n",
    "5. Evaluation of the models on test data.\n",
    "\n",
    "Rather than recapitulate all of these component tasks for each application, standard packages have been developed to facilitate them. In order to facilitate your own experimentation, it's time to make use of some of these packages to scale up your ability to build and test models. That is the subject of this lab.\n",
    "\n",
    "Torchtext datasets provide a uniform system for establishing dataset objects that contain multiple examples, each of which may have multiple named fields. These fields themselves have specifications that tell whether the data in that field is sequential (like text sequences) or simple (like class labels); whether and how to preprocess, tokenize, or postprocess the data; and many other properties. Dataset objects can be easily split into parts (training and test, for instance), or turned into a sequence of small batches for processing by models.\n",
    "\n",
    "This lab provides an introduction to using `torchtext` and PyTorch in preparation for its appearance in later labs and project segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n",
    "\n",
    "* [`torch.Tensor.backward`](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.backward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import torch\n",
    "import torch.distributions as ds\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext as tt\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "# Otter grader which we use for grading does not support\n",
    "# !command, so we need to use shell(command) instead\n",
    "# to run shell commands\n",
    "def shell(str):\n",
    "    file = os.popen(str)\n",
    "    result = file.read()\n",
    "    print (result)\n",
    "    if file.close () is not None:\n",
    "        print ('failed')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "# Random seed\n",
    "random_seed = 1234\n",
    "## GPU check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Manipulating text corpora with `torchtext`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll use `torchtext` to load the _Green Eggs and Ham_ (GEaH) dataset.\n",
    "\n",
    "We start with reading in the data and performing some ad hoc cleaning (removing comment lines and blank lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_file(text):\n",
    "    \"\"\"strip #comments and empty lines from a string\"\"\"\n",
    "    result = \"\"\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()              # trim whitespace\n",
    "        line = re.sub('#.*$', '', line)  # trim comments\n",
    "        if line != '':                   # drop blank lines\n",
    "            result += line + '\\n'\n",
    "    return result\n",
    "\n",
    "# Read the GEaH data and write out a corresponding TSV file\n",
    "shell('wget -nv -N -P data \"https://github.com/nlp-course/data/raw/master/Seuss/seuss - 1960 - green eggs and ham.txt\"')\n",
    "with open('data/seuss - 1960 - green eggs and ham.txt', 'r') as fin:\n",
    "    with open('data/geah.tsv', 'w') as fout:\n",
    "        fout.write(strip_file(fin.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing training and test datasets\n",
    "\n",
    "Take a look at the file `geah.tsv`, which we've just processed and placed into the sibling `data` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell('head \"data/geah.tsv\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Notice the structure of this corpus. Each line contains a sentence from the book, preceded by a label that provides the speaker of that sentence. The speaker and sentence are separated by a tab character. The data is thus set up properly for a [`torchtext.data.TabularDataset`](https://pytorch.org/text/data.html#torchtext.data.TabularDataset) using its `\"TSV\"` (tab-separated values) format.\n",
    "\n",
    "In order to establish a `torchtext.data.TabularDataset` object for dealing with the GEaH dataset, you'll first need to establish the two fields (via [`torchtext.data.Field`](https://pytorch.org/text/data.html#field)), one for the label (the speaker) and one for the text, which you should call `LABEL` and `TEXT`, respectively.\n",
    "\n",
    "When setting up a field with `torchtext.data.Field`, you'll want to consider whether you want to further specify the values for the various keyword arguments listed [here](https://torchtext.readthedocs.io/en/latest/data.html#field), or to leave the default values.\n",
    "\n",
    "With respect to the tokenization of the text field, you should use the `torchtext` \"basic_english\" tokenizer introduced in lab 1-1 for the text field and lowercase all tokens.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: fields_setup\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "LABEL = (\n",
    "    ...\n",
    ")\n",
    "    \n",
    "TEXT = (\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"fields_setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, you can set up the dataset using `torchtext.data.TabularDataSet`. It should look for the TSV data in the file `data/geah/tsv`, and should use the names `label` and `field` for the two fields in the tabular data.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: dataset_setup\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "geah = (\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "All [`torchtext.data.Dataset`](https://pytorch.org/text/data.html#torchtext.data.Dataset) objects have a [`split`](https://pytorch.org/text/data.html#torchtext.data.Dataset.split) method that splits the dataset into two or three pieces, for instance, to have a separate training and test set. Use the `split` method to generate a 70%/30% split of the GEaH corpus into two subsets called `train` and `test`.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: dataset_split\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "train, test = geah.split() # Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fields can have a ssociated with them a _vocabulary_ consisiting of all of the possible values that are used in that field in a particular dataset. The vocabulary establishes the kind of indexing scheme between types and indices that we explored in lab 1-1. We will use the training corpus to establish vocabularies for the two fields `LABEL` and `TEXT` using the [`build_vocab`](https://pytorch.org/text/data.html#torchtext.data.Field.build_vocab) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train)\n",
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The `TEXT` and `LABEL` fields, objects of class [`torchtext.data.Field`](https://pytorch.org/text/data.html#field), now have vocabularies associated with them, accessible in their respective `vocab` fields. How many elements are there in these vocabularies? You can use the `len` function to find out.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: vocab_sizes\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "label_vocab_size = len(LABEL.vocab) # Solution\n",
    "text_vocab_size = len(TEXT.vocab)   # Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"vocab_sizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"label vocabulary size is {label_vocab_size}\\n\"\n",
    "      f\"text vocabulary size is {text_vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there three elements in the `LABEL` vocabulary, given that there are only two speakers, Guy and Sam? We can find out by examining the `LABEL` vocabulary more closely. `Field` vocabulary objects have an especially useful `stoi` data field, whose value is a dictionary that maps the elements of the vocabulary to integer index representations of the elements. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** What is the unexpected third element in the label vocabulary? Why do you think it's there?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_third_element\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "> As described in more detail in [the `torchtext` documentation](https://torchtext.readthedocs.io/en/latest/vocab.html#torchtext.vocab.Vocab), there's also an `itos` data field for conversion of vocabulary items from the index representation to the original values and a `freqs` data field that keeps a frequency distribution for the items in the vocabulary as a `collections.Counter` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Operations over datasets\n",
    "\n",
    "We now have training and test datasets. You can experiment with the kinds of operations you'll need to do to implement models like Naive Bayes or logistic regression.\n",
    "\n",
    "For instance, you might need to iterate over the different class labels (the vocabulary of the `LABEL` field) or the word types (the vocabulary of the `TEXT` field). Define a function that iterates over the vocabulary of a field and prints each one out like this:\n",
    "```\n",
    ">>> print_vocab(LABEL)\n",
    "<unk>\n",
    "GUY\n",
    "SAM\n",
    "```\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: print_vocab\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "def print_vocab(field):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"print_vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can use the `print_vocab` function to print out the different class labels in the `LABEL` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_vocab(LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Other simple calculations that will be useful in implementing the various models:\n",
    "\n",
    "1. Counting how many instances there are in a dataset.\n",
    "2. Counting how many instances of a certain class there are in a data set.\n",
    "3. Counting how many tokens of a certain type there are in the text of an instance.\n",
    "\n",
    "Let's write functions for these. They'll come in handy in the first problem set.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: count_instances\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - 1. Counting how many instances there are in a dataset.\n",
    "def count_instances(dataset):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"count_instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - 2. Counting how many instances of a certain class there are in a data set.\n",
    "def count_instances_class(dataset, label):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"count_instances_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - 3. Counting how many tokens of a certain type there are in the text of an instance.\n",
    "def count_tokens_instance(instance, tokentype):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"count_tokens_instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training and testing with PyTorch\n",
    "\n",
    "Past labs have shown that all of the detail about \n",
    "\n",
    "* establishing models and their parameters,\n",
    "* using them to calculate the outputs for some inputs, \n",
    "* training them to optimize the parameters via stochastic gradient descent, and \n",
    "* evaluating them by testing on held-out data\n",
    "\n",
    "is tedious to manage. Fortunately, it is also so formulaic, at least for a certain class of models, that general tools can be deployed to manage the process. In the remainder of this lab, you'll use one such tool, PyTorch. For simplicity, rather than a natural-language task, you'll be training a model to fit a curve; it has an especially simple structure: one scalar input and one scalar output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating training and test data\n",
    "\n",
    "We start by generating some training and test data. The data is generated as a noisy sine function, calculated by the function `sinusoid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoid(x, amplitude=1., phase=0., frequency=1., noise=0.):\n",
    "    \"\"\"Returns the values on input(s) `x` of a sinusoid determined by `amplitude`, \n",
    "       `phase`, and angular `frequency`, with some added normal noise with variance \n",
    "       given by `noise`.\"\"\"\n",
    "    normal_noise = ds.normal.Normal(torch.tensor([0.0]), torch.tensor([noise]))\n",
    "    noise_sample = torch.tensor([normal_noise.sample() for i in range(len(x))])\n",
    "    y = amplitude * torch.sin(x * frequency + phase) + noise_sample\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate data for training and testing by sampling this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_input(func, count, bound, **kwargs):\n",
    "    \"\"\"Returns `count` samples of x-y pairs of function `func`, with the x \n",
    "       values sampled uniformly between +/-`bound`. The `kwargs` are passed\n",
    "       on to `func`.\"\"\"\n",
    "    input_unif = ds.uniform.Uniform(-bound, +bound)\n",
    "    x = input_unif.sample(torch.Size([count]))\n",
    "    y = func(x, **kwargs)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give a sense of what a data sample looks like, we plot a sample of 100 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(data):\n",
    "    \"\"\"Plots `data` given as a single pair of inmputs and outputs.\"\"\"\n",
    "    X, Y = data\n",
    "    plt.plot(X.numpy(), Y.numpy(), '.')\n",
    "    plt.xlabel('Input')\n",
    "    plt.ylabel('Output')\n",
    "    # we cannot use plt.show() because otter-grader does not support it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(sample_input(sinusoid, 100, 5, noise=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a feed-forward neural network\n",
    "\n",
    "<img src=\"https://github.com/nlp-course/data/raw/feature/ffnnfig/Resources/ffnn-example.png\" width=33% align=right />\n",
    "The model that we will train to predict the output of this function based on a sample will consist of a series of sublayers as depicted in the figure at right. At the bottom of the figure, we start with $\\vect{x}$, the scalar input (of dimensionality $1$ as shown in the \"shape\" designation). The first layer is a perceptron layer, with a linear sublayer (with weights $\\vect{U}$) followed by a sigmoid sublayer. Since $U$ is of dimenionality $1 \\times D$, the output is a vector of dimensionality $D$. (We refer to $D$ as the hidden dimension.) Then comes another perceptron layer with output of dimensionality $D$. Finally, a single linear layer reduces the dimensionality back to the predicted scalar output $\\tilde{y}$ of dimensionality $1$. The loss is calculated as the mean square error of $\\tilde{y}$ relative to $y$. (In this case, the mean is irrelevant, since $y$ is a scalar.)\n",
    "\n",
    "We define a class `FFNN`, which inherits from the `nn.Module` class, PyTorch's class for neural network models. It takes an argument `hidden_dim` which is the size of the hidden layers, $D$ in the figure.\n",
    "\n",
    "The parameters of this model â€“ the values that will be adjusted to minimize the loss â€“ are the elements of the tensors $\\vect{U}$, $\\vect{V}$, and $\\vect{W}$. Those parameters are created and tracked when the corresponding sublayers are created using `nn.Linear`. That's the wonder of using PyTorch â€“ so much happens under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, init_low=-2, init_high=2):\n",
    "        super().__init__()\n",
    "        # dimensionality of hidden layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # the sublayers, two perceptrons and a final linear layer\n",
    "        self.sublayer1 = nn.Linear(1, hidden_dim) \n",
    "        self.sublayer2 = nn.Sigmoid() \n",
    "        self.sublayer3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.sublayer4 = nn.Sigmoid() \n",
    "        self.sublayer5 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        # initialize parameters\n",
    "        torch.manual_seed(random_seed)\n",
    "        for p in self.parameters():\n",
    "            p.data.uniform_(init_low, init_high)\n",
    "        # save a copy of the parameters to allow resetting\n",
    "        self.init_state = copy.deepcopy(self.state_dict())\n",
    "\n",
    "    # Resetting state: If you want to rerun a model, say with a different\n",
    "    # training regime, you can reset the model's parameter state using\n",
    "    #    model.reset_state()\n",
    "    # before retraining, e.g., \n",
    "    #    train_model(model, criterion, optim, train_data, n_epochs=50)\n",
    "    def reset_state(self):\n",
    "        self.load_state_dict(copy.deepcopy(self.init_state))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first perceptron layer\n",
    "        z = self.sublayer2(self.sublayer1(x))\n",
    "        # second perceptron layer\n",
    "        z_prime = self.sublayer4(self.sublayer3(z))\n",
    "        # final linear layer\n",
    "        return self.sublayer5(z_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a model by instantiating the `FFNN` class. We'll do so with a hidden dimension of 4, being careful to move the model with its parameters to the device we're using for calculations (a GPU if one is available, as on Google Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIMENSION = 4\n",
    "model = FFNN(HIDDEN_DIMENSION).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the criterion to be optimized as the mean square error loss function provided by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='mean') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating data according to a model\n",
    "\n",
    "To evaluate how well the model performs on some test data, we run the model forward on the $x$ values and compute the loss relative to the $y$ values. We define a function `eval_model` to carry out this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, criterion, data):\n",
    "    \"\"\"Applies the `model` to the x values in the `data` and returns the\n",
    "       loss relative to the y values in the data along with the predicted \n",
    "       y values.\"\"\"\n",
    "    model.eval()                          # turn on evaluation mode\n",
    "    with torch.no_grad():                 # turn off propagating gradients\n",
    "        X, Y = data                       # extract x and y values\n",
    "        X = X.view(-1, 1).to(device)      # convert x and y to column vectors\n",
    "        Y = Y.view(-1, 1).to(device)      # ...and move them to the device\n",
    "        predictions = model(X)            # calculate the predicted y values\n",
    "        loss = criterion(predictions, Y)  # see how far off they are\n",
    "    return loss.item(), predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that remains is training the model. We'll use one of PyTorch's built in optimizers, the `Adam` optimizer. We set a few parameters for the training process: the learning rate, the number of \"epochs\" (passes through the training data) to perform, and the number of examples to train on at a time (the \"batch size\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters of the training regimen\n",
    "LEARNING_RATE = 0.003\n",
    "NUMBER_EPOCHS = 25\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "## Choices for optimizers\n",
    "# Stochastic Gradient Descent (SGD) optimizer\n",
    "# optim = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "# The Adam optimizer, as described in the paper:\n",
    "# Kingma and Ba. 2014. Adam: A Method for Stochastic Optimization.\n",
    "# [https://arxiv.org/abs/1412.6980]\n",
    "optim = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the parameters of a model\n",
    "\n",
    "Finally, we get to the function to train the parameters of the model so as to best fit the predictions to the actual values. We've provided the code, except for a few lines that you'll need to provide (marked `#TODO`), making use of some of the tools defined above. Those lines, which form the heart of the computation, calculate \"forwards\" to get the output predictions for the inputs, calculate the loss for those predictions, and calculate \"backwards\" the gradients of the loss for each of the parameters of the model. This sets up the optimizer to take a step of updating the parameters, making use of the calculated gradients to determine the direction to step. The saved gradients can then be zeroed and the process repeated.\n",
    "\n",
    "> Note: The code we're asking you to write is *tiny*. If you find yourself writing more than a short line of code per `#TODO`, you're missing something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, data,\n",
    "                n_epochs=NUMBER_EPOCHS, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Optimizes the parameters of the `model` by minimizing the `criterion`\n",
    "       on the training `data`, using the `optimizer` algorithm for updates.\"\"\"    \n",
    "    model.train()                     # Turn on training mode\n",
    "\n",
    "    X, Y = data\n",
    "    trainX_len = len(X)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        loss_per_epoch = 0.\n",
    "        for batch_i in range(int(trainX_len/batch_size)):\n",
    "            optimizer.zero_grad()     # new batch; zero the gradients of the parameters\n",
    "            \n",
    "            # Input tensors and their corresponding output values for this batch\n",
    "            batch_X = (X[batch_i * batch_size\n",
    "                         : (batch_i+1) * batch_size] # extract examples in batch\n",
    "                       .view(-1, 1)                  # reshape to column vector\n",
    "                       .to(device)                   # move to device\n",
    "                      )\n",
    "            batch_Y = (Y[batch_i * batch_size \n",
    "                         : (batch_i+1) * batch_size]\n",
    "                       .view(-1, 1)\n",
    "                       .to(device)\n",
    "                      )\n",
    "            \n",
    "            #TODO: Calculate predictions for the x values in this batch\n",
    "            predictions = model(batch_X)               #Solution\n",
    "            \n",
    "            #TODO: Calculate the loss for the predictions\n",
    "            loss = criterion(predictions, batch_Y)     #Solution\n",
    "            \n",
    "            #TODO: Perform backpropagation to update all of the parameters\n",
    "            loss.backward()                            #Solution\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_per_epoch += loss.item()\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1:3d}  Total loss: {loss_per_epoch:8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Let's try it out. We start by generating some training and test data. The training data will be 10,000 samples of a noisy sinusoid. The test data, 100 samples from the same sinusoid, will be noise-free, so we can see how close the predictions are to noise-free outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sample_input(sinusoid, 10000, 5., frequency=1.5, noise=0.05)\n",
    "test_data = sample_input(sinusoid, 100, 5., frequency=1.5)\n",
    "\n",
    "plot_sample(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_state()\n",
    "train_model(model, criterion, optim, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and test the trained model by evaluating it on the the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, predictions = eval_model(model, criterion, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how well the model works by plotting the test data (circles) along with the predicted values (crosses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(data, predictions):\n",
    "    X, Y = data\n",
    "    \n",
    "    # Plot the actual output values\n",
    "    plt.plot(X.cpu().numpy(), Y.cpu().numpy(), '.', label = 'Target Values')\n",
    "    \n",
    "    # Plot the predicted output values\n",
    "    predictions = predictions.view(-1, 1)\n",
    "    plt.plot(X.cpu().numpy(), predictions.cpu().numpy(), 'x', label = 'Predictions')\n",
    "    \n",
    "    plt.xlabel('Input')\n",
    "    plt.ylabel('Output')\n",
    "    plt.legend()\n",
    "    # we cannot use plt.show() because otter-grader does not support it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions\n",
    "visualize_predictions(test_data, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different models\n",
    "\n",
    "Now that we have the infrastructure, try experimenting with different models. Here are a few things you might play with. (No need to try them all.) What happens if you change the hidden dimension, increasing it to 8 or decreasing it to 2? What happens if you drop the middle layer? What about no middle layer but a much higher hidden dimension size? Does running for more epochs improve performance? Does the SGD optimizer work better or worse than the Adam optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** What conclusions have you drawn from your experimentation?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_testing_models\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# End of lab 1-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
